{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "# Your code goes here #\n",
    "#######################\n",
    "data = pd.read_csv('./spambase.data', header=None)\n",
    "labels = np.array((data[len(data.columns)-1].values.tolist()))\n",
    "del data[len(data.columns)-1]\n",
    "data = np.array(data.values.tolist())\n",
    "X, y = shuffle(data, labels, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.delete(X, [46 ], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "# Your code goes here #\n",
    "#######################\n",
    "def norm1(X):\n",
    "    temp = X.copy()\n",
    "    min = np.amin(temp, axis = 0)\n",
    "    temp -= min\n",
    "    max = np.max(temp, axis = 0)\n",
    "    temp /= max\n",
    "    return temp\n",
    "def norm2(X):\n",
    "    temp = X.copy()\n",
    "    temp = (temp - np.mean(temp, axis = 0))/np.std(temp, axis = 0)\n",
    "    return temp\n",
    "\n",
    "\n",
    "norm1_x = norm1(X)\n",
    "norm2_x = norm2(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "# Your code goes here #\n",
    "#######################\n",
    "test_precentage = 20\n",
    "def split(X, y, test_precentage):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=test_precentage/100, random_state=0)\n",
    "    return x_train, x_test, y_train, y_test\n",
    "x_train, x_test, y_train, y_test = split(norm2_x, y, test_precentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Accuracy, over 15 validations: 99.92236043537565%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Training Set Accuracy</th>\n",
       "      <th>Validation Set Accuracy</th>\n",
       "      <th>Testing Set Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99.941759</td>\n",
       "      <td>89.430894</td>\n",
       "      <td>91.530945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99.941759</td>\n",
       "      <td>91.463415</td>\n",
       "      <td>91.313789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99.912638</td>\n",
       "      <td>92.682927</td>\n",
       "      <td>90.770901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99.912638</td>\n",
       "      <td>89.837398</td>\n",
       "      <td>91.096634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99.912638</td>\n",
       "      <td>89.837398</td>\n",
       "      <td>90.553746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>99.912664</td>\n",
       "      <td>92.653061</td>\n",
       "      <td>90.879479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>99.912664</td>\n",
       "      <td>91.836735</td>\n",
       "      <td>90.336591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>99.912664</td>\n",
       "      <td>90.204082</td>\n",
       "      <td>90.010858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>99.970888</td>\n",
       "      <td>90.204082</td>\n",
       "      <td>92.290988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>99.912664</td>\n",
       "      <td>91.020408</td>\n",
       "      <td>91.422367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>99.941776</td>\n",
       "      <td>89.795918</td>\n",
       "      <td>92.290988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>99.912664</td>\n",
       "      <td>92.653061</td>\n",
       "      <td>91.096634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>99.912664</td>\n",
       "      <td>88.163265</td>\n",
       "      <td>91.096634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>99.912664</td>\n",
       "      <td>93.061224</td>\n",
       "      <td>90.879479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>99.912664</td>\n",
       "      <td>91.020408</td>\n",
       "      <td>90.879479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics     Training Set Accuracy  Validation Set Accuracy  \\\n",
       "Validation                                                   \n",
       "0                       99.941759                89.430894   \n",
       "1                       99.941759                91.463415   \n",
       "2                       99.912638                92.682927   \n",
       "3                       99.912638                89.837398   \n",
       "4                       99.912638                89.837398   \n",
       "5                       99.912664                92.653061   \n",
       "6                       99.912664                91.836735   \n",
       "7                       99.912664                90.204082   \n",
       "8                       99.970888                90.204082   \n",
       "9                       99.912664                91.020408   \n",
       "10                      99.941776                89.795918   \n",
       "11                      99.912664                92.653061   \n",
       "12                      99.912664                88.163265   \n",
       "13                      99.912664                93.061224   \n",
       "14                      99.912664                91.020408   \n",
       "\n",
       "Metrics     Testing Set Accuracy  \n",
       "Validation                        \n",
       "0                      91.530945  \n",
       "1                      91.313789  \n",
       "2                      90.770901  \n",
       "3                      91.096634  \n",
       "4                      90.553746  \n",
       "5                      90.879479  \n",
       "6                      90.336591  \n",
       "7                      90.010858  \n",
       "8                      92.290988  \n",
       "9                      91.422367  \n",
       "10                     92.290988  \n",
       "11                     91.096634  \n",
       "12                     91.096634  \n",
       "13                     90.879479  \n",
       "14                     90.879479  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def k_fold_validation(k, x, y):\n",
    "    '''\n",
    "    the function each of the k splits, val \n",
    "    and train sets data and labels\n",
    "    '''\n",
    "    k_folds = KFold(n_splits=k)\n",
    "    splits = []\n",
    "    for train_index, val_index in k_folds.split(x, y):\n",
    "        splits += [{\"x_train\":x[train_index], \"x_val\":x[val_index], \"y_train\":y[train_index], \"y_val\":y[val_index]}]\n",
    "    return splits\n",
    "\n",
    "def k_fold_performance(splits):\n",
    "    '''\n",
    "    This function returns the models\n",
    "    (decision trees) and their corresponding accuracies\n",
    "    when the dataset is given in the format of the return\n",
    "    object of the above function\n",
    "    '''\n",
    "    performance = dict()\n",
    "    performance['Training Set Accuracy'] = []\n",
    "    performance['Validation Set Accuracy'] = []\n",
    "    performance['Testing Set Accuracy'] = []\n",
    "    trees = []\n",
    "    for i in range(len(splits)):\n",
    "        split = splits[i]\n",
    "        train_set = split['x_train']\n",
    "        val_set = split['x_val']\n",
    "        val_y = split['y_val']\n",
    "        train_y = split['y_train']\n",
    "        clf = DecisionTreeClassifier()\n",
    "        clf.fit(train_set, train_y)\n",
    "        trees += [clf]\n",
    "        performance['Training Set Accuracy'] += [clf.score(train_set, train_y)*100]\n",
    "        performance['Validation Set Accuracy'] += [clf.score(val_set, val_y)*100]\n",
    "        performance['Testing Set Accuracy'] += [clf.score(x_test, y_test)*100]\n",
    "    return performance, trees\n",
    "\n",
    "# Initialize K and split the data\n",
    "\n",
    "k = 15\n",
    "\n",
    "# Splitting and evaluating\n",
    "\n",
    "performance, trees = k_fold_performance(k_fold_validation(k, x_train, y_train))\n",
    "print(f\"Average Training Accuracy, over {k} validations: {sum(performance['Training Set Accuracy'])/len(performance['Training Set Accuracy'])}%\")\n",
    "\n",
    "# This contains the tree models, and their respective performances\n",
    "\n",
    "df = pd.DataFrame(performance)\n",
    "df.index.names = ['Validation']\n",
    "df.columns.names = ['Metrics']\n",
    "df\n",
    "\n",
    "#Run the K fold Validation and report the scores\n",
    "\n",
    "#######################\n",
    "# Your code goes here #\n",
    "#######################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the testing Set (Random Forests): 95.33116178067318%\n",
      "Accuracy on the testing Set (Random Forests): 95.65689467969598%\n",
      "Accuracy on the testing Set (Random Forests): 95.33116178067318%\n",
      "Accuracy on the testing Set (Random Forests): 95.98262757871878%\n",
      "Accuracy on the testing Set (Random Forests): 95.43973941368078%\n",
      "Accuracy on the testing Set (Random Forests): 95.43973941368078%\n",
      "Accuracy on the testing Set (Random Forests): 95.33116178067318%\n",
      "Accuracy on the testing Set (Random Forests): 96.09120521172639%\n",
      "Accuracy on the testing Set (Random Forests): 95.43973941368078%\n",
      "Accuracy on the testing Set (Random Forests): 95.33116178067318%\n",
      "Accuracy on the testing Set (Random Forests): 95.54831704668838%\n",
      "Accuracy on the testing Set (Random Forests): 95.65689467969598%\n",
      "Accuracy on the testing Set (Random Forests): 95.65689467969598%\n",
      "Accuracy on the testing Set (Random Forests): 96.19978284473399%\n",
      "Accuracy on the testing Set (Random Forests): 95.65689467969598%\n",
      "Accuracy on the testing Set (Random Forests): 95.54831704668838%\n",
      "Accuracy on the testing Set (Random Forests): 95.65689467969598%\n",
      "Accuracy on the testing Set (Random Forests): 95.54831704668838%\n",
      "Accuracy on the testing Set (Random Forests): 95.22258414766557%\n",
      "Accuracy on the testing Set (Random Forests): 95.98262757871878%\n",
      "Accuracy on the testing Set (Random Forests): 94.89685124864278%\n",
      "Accuracy on the testing Set (Random Forests): 95.54831704668838%\n",
      "Accuracy on the testing Set (Random Forests): 95.43973941368078%\n",
      "Accuracy on the testing Set (Random Forests): 95.22258414766557%\n",
      "Accuracy on the testing Set (Random Forests): 95.65689467969598%\n",
      "Accuracy on the testing Set (Random Forests): 95.54831704668838%\n",
      "Accuracy on the testing Set (Random Forests): 95.87404994571118%\n",
      "Accuracy on the testing Set (Random Forests): 95.76547231270358%\n",
      "Accuracy on the testing Set (Random Forests): 95.65689467969598%\n",
      "Accuracy on the testing Set (Random Forests): 95.87404994571118%\n",
      "Accuracy on the testing Set (Random Forests): 95.33116178067318%\n",
      "Accuracy on the testing Set (Random Forests): 95.54831704668838%\n",
      "Accuracy on the testing Set (Random Forests): 95.54831704668838%\n",
      "Accuracy on the testing Set (Random Forests): 95.76547231270358%\n",
      "Accuracy on the testing Set (Random Forests): 96.19978284473399%\n",
      "Accuracy on the testing Set (Random Forests): 95.65689467969598%\n",
      "Accuracy on the testing Set (Random Forests): 95.33116178067318%\n",
      "Accuracy on the testing Set (Random Forests): 95.65689467969598%\n",
      "Accuracy on the testing Set (Random Forests): 95.65689467969598%\n",
      "Accuracy on the testing Set (Random Forests): 95.33116178067318%\n",
      "Accuracy on the testing Set (Random Forests): 95.22258414766557%\n",
      "Accuracy on the testing Set (Random Forests): 95.54831704668838%\n",
      "Accuracy on the testing Set (Random Forests): 95.54831704668838%\n",
      "Accuracy on the testing Set (Random Forests): 95.76547231270358%\n",
      "Accuracy on the testing Set (Random Forests): 95.43973941368078%\n",
      "Accuracy on the testing Set (Random Forests): 95.76547231270358%\n",
      "Accuracy on the testing Set (Random Forests): 95.65689467969598%\n",
      "Accuracy on the testing Set (Random Forests): 95.54831704668838%\n",
      "Accuracy on the testing Set (Random Forests): 95.87404994571118%\n",
      "Accuracy on the testing Set (Random Forests): 95.54831704668838%\n",
      "0.9558957654723127\n"
     ]
    }
   ],
   "source": [
    "def ensemble_components(components, x_train, y_train, n_prime):\n",
    "    ensemble = []\n",
    "    for _ in range(components):\n",
    "        clf = DecisionTreeClassifier(max_features= 5)\n",
    "        # Selecting features\n",
    "        rand_idx = np.random.randint(0, x_train.shape[0], n_prime)\n",
    "        train_labels = y_train[rand_idx]\n",
    "        train_set = x_train[rand_idx]\n",
    "        # bagging \n",
    "        clf.fit(train_set, train_labels)\n",
    "        ensemble += [clf]\n",
    "    return ensemble\n",
    "\n",
    "def random_forest_algorithm(number_of_trees, x_train, y_train, n_prime): # Pass necessary params as per requirements\n",
    "    '''\n",
    "    This function intends to return the indivdual trees,\n",
    "    which are going to be used for predicting the ensemble\n",
    "    '''\n",
    "    ensemble = ensemble_components(number_of_trees, x_train, y_train, n_prime)\n",
    "    return ensemble\n",
    "\n",
    "\n",
    "def test(ensemble, test_set, test_labels):\n",
    "    preds = [i.predict(test_set) for i in ensemble]\n",
    "    preds = np.array(preds)\n",
    "    preds = np.mean(preds, axis = 0)\n",
    "    for i in range(len(preds)):\n",
    "        if(preds[i] >= 0.5):\n",
    "            preds[i] = 1\n",
    "        else:\n",
    "            preds[i] = 0\n",
    "    preds = preds.astype(int)\n",
    "    score = accuracy_score(test_labels, preds)\n",
    "    return preds, score\n",
    "\n",
    "temp_1 = []\n",
    "for _ in range(50):\n",
    "    ensembles = random_forest_algorithm(100, x_train, y_train,( (len(x_train)*9)//10))\n",
    "    test_preds, score = test(ensembles, x_test, y_test)\n",
    "    print(f\"Accuracy on the testing Set (Random Forests): {score*100}%\")\n",
    "    temp_1 += [score]\n",
    "print(np.mean(temp_1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#######################\n",
    "# Your code goes here #\n",
    "#######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9619978284473398"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(temp_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = [\n",
    "0.30536\n",
    ",1.2906\n",
    ",0.50414\n",
    ",1.3952\n",
    ",0.67251\n",
    ",0.27382\n",
    ",0.39144\n",
    ",0.40107\n",
    ",0.27862\n",
    ",0.64476\n",
    ",0.20154\n",
    ",0.8617\n",
    ",0.30104\n",
    ",0.33518\n",
    ",0.25884\n",
    ",0.82579\n",
    ",0.44406\n",
    ",0.53112\n",
    ",1.7755\n",
    ",0.50977\n",
    ",1.2008\n",
    ",1.0258\n",
    ",0.35029\n",
    ",0.44264\n",
    ",1.6713\n",
    ",0.88696\n",
    ",3.3673\n",
    ",0.53858\n",
    ",0.59333\n",
    ",0.45668\n",
    ",0.40339\n",
    ",0.32856\n",
    ",0.55591\n",
    ",0.32945\n",
    ",0.53226\n",
    ",0.40262\n",
    ",0.42345\n",
    ",0.22065\n",
    ",0.43467\n",
    ",0.34992\n",
    ",0.3612\n",
    ",0.76682\n",
    ",0.22381\n",
    ",0.62198\n",
    ",1.0117\n",
    ",0.91112\n",
    ",0.076274\n",
    ",0.28573\n",
    ",0.24347\n",
    ",0.27036\n",
    ",0.10939\n",
    ",0.81567\n",
    ",0.24588\n",
    ",0.42934\n",
    ",31.729\n",
    ",194.89\n",
    ",606.35\n",
    ",0.4887\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([46, 50, 10, 37, 42, 48, 52, 14, 49,  5,  8, 47, 12,  0, 31, 33, 13,\n",
       "       39, 22, 40,  6,  7, 35, 30, 36, 53, 38, 23, 16, 29, 57,  2, 19, 17,\n",
       "       34, 27, 32, 28, 43,  9,  4, 41, 51, 15, 11, 25, 45, 44, 21, 20,  1,\n",
       "        3, 24, 18, 26, 54, 55, 56])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
