{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "# Your code goes here #\n",
    "#######################\n",
    "data = pd.read_csv('./spambase.data', header=None)\n",
    "labels = np.array((data[len(data.columns)-1].values.tolist()))\n",
    "del data[len(data.columns)-1]\n",
    "data = np.array(data.values.tolist())\n",
    "X, y = shuffle(data, labels, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.delete(X, [39, 40, 51, 33], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "# Your code goes here #\n",
    "#######################\n",
    "def norm1(X):\n",
    "    temp = X.copy()\n",
    "    min = np.amin(temp, axis = 0)\n",
    "    temp -= min\n",
    "    max = np.max(temp, axis = 0)\n",
    "    temp /= max\n",
    "    return temp\n",
    "def norm2(X):\n",
    "    temp = X.copy()\n",
    "    temp = (temp - np.mean(temp, axis = 0))/np.std(temp, axis = 0)\n",
    "    return temp\n",
    "\n",
    "\n",
    "norm1_x = norm1(X)\n",
    "norm2_x = norm2(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "# Your code goes here #\n",
    "#######################\n",
    "test_precentage = 20\n",
    "def split(X, y, test_precentage):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=test_precentage/100, random_state=0)\n",
    "    return x_train, x_test, y_train, y_test\n",
    "x_train, x_test, y_train, y_test = split(norm1_x, y, test_precentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Accuracy, over 15 validations: 99.87189440752448%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>Training Set Accuracy</th>\n",
       "      <th>Validation Set Accuracy</th>\n",
       "      <th>Testing Set Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99.883518</td>\n",
       "      <td>89.430894</td>\n",
       "      <td>91.856678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99.912638</td>\n",
       "      <td>91.463415</td>\n",
       "      <td>91.856678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99.854397</td>\n",
       "      <td>92.682927</td>\n",
       "      <td>92.073833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99.854397</td>\n",
       "      <td>91.463415</td>\n",
       "      <td>91.530945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99.854397</td>\n",
       "      <td>91.056911</td>\n",
       "      <td>92.182410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>99.854440</td>\n",
       "      <td>95.102041</td>\n",
       "      <td>91.205212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>99.854440</td>\n",
       "      <td>94.285714</td>\n",
       "      <td>91.639522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>99.854440</td>\n",
       "      <td>93.469388</td>\n",
       "      <td>92.616721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>99.912664</td>\n",
       "      <td>88.571429</td>\n",
       "      <td>91.422367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>99.854440</td>\n",
       "      <td>91.020408</td>\n",
       "      <td>92.508143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>99.912664</td>\n",
       "      <td>88.979592</td>\n",
       "      <td>92.290988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>99.883552</td>\n",
       "      <td>92.653061</td>\n",
       "      <td>92.182410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>99.854440</td>\n",
       "      <td>92.653061</td>\n",
       "      <td>91.965255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>99.883552</td>\n",
       "      <td>93.469388</td>\n",
       "      <td>91.530945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>99.854440</td>\n",
       "      <td>93.469388</td>\n",
       "      <td>92.725299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics     Training Set Accuracy  Validation Set Accuracy  \\\n",
       "Validation                                                   \n",
       "0                       99.883518                89.430894   \n",
       "1                       99.912638                91.463415   \n",
       "2                       99.854397                92.682927   \n",
       "3                       99.854397                91.463415   \n",
       "4                       99.854397                91.056911   \n",
       "5                       99.854440                95.102041   \n",
       "6                       99.854440                94.285714   \n",
       "7                       99.854440                93.469388   \n",
       "8                       99.912664                88.571429   \n",
       "9                       99.854440                91.020408   \n",
       "10                      99.912664                88.979592   \n",
       "11                      99.883552                92.653061   \n",
       "12                      99.854440                92.653061   \n",
       "13                      99.883552                93.469388   \n",
       "14                      99.854440                93.469388   \n",
       "\n",
       "Metrics     Testing Set Accuracy  \n",
       "Validation                        \n",
       "0                      91.856678  \n",
       "1                      91.856678  \n",
       "2                      92.073833  \n",
       "3                      91.530945  \n",
       "4                      92.182410  \n",
       "5                      91.205212  \n",
       "6                      91.639522  \n",
       "7                      92.616721  \n",
       "8                      91.422367  \n",
       "9                      92.508143  \n",
       "10                     92.290988  \n",
       "11                     92.182410  \n",
       "12                     91.965255  \n",
       "13                     91.530945  \n",
       "14                     92.725299  "
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def k_fold_validation(k, x, y):\n",
    "    '''\n",
    "    the function each of the k splits, val \n",
    "    and train sets data and labels\n",
    "    '''\n",
    "    k_folds = KFold(n_splits=k)\n",
    "    splits = []\n",
    "    for train_index, val_index in k_folds.split(x, y):\n",
    "        splits += [{\"x_train\":x[train_index], \"x_val\":x[val_index], \"y_train\":y[train_index], \"y_val\":y[val_index]}]\n",
    "    return splits\n",
    "\n",
    "def k_fold_performance(splits):\n",
    "    '''\n",
    "    This function returns the models\n",
    "    (decision trees) and their corresponding accuracies\n",
    "    when the dataset is given in the format of the return\n",
    "    object of the above function\n",
    "    '''\n",
    "    performance = dict()\n",
    "    performance['Training Set Accuracy'] = []\n",
    "    performance['Validation Set Accuracy'] = []\n",
    "    performance['Testing Set Accuracy'] = []\n",
    "    trees = []\n",
    "    for i in range(len(splits)):\n",
    "        split = splits[i]\n",
    "        train_set = split['x_train']\n",
    "        val_set = split['x_val']\n",
    "        val_y = split['y_val']\n",
    "        train_y = split['y_train']\n",
    "        clf = DecisionTreeClassifier()\n",
    "        clf.fit(train_set, train_y)\n",
    "        trees += [clf]\n",
    "        performance['Training Set Accuracy'] += [clf.score(train_set, train_y)*100]\n",
    "        performance['Validation Set Accuracy'] += [clf.score(val_set, val_y)*100]\n",
    "        performance['Testing Set Accuracy'] += [clf.score(x_test, y_test)*100]\n",
    "    return performance, trees\n",
    "\n",
    "# Initialize K and split the data\n",
    "\n",
    "k = 15\n",
    "\n",
    "# Splitting and evaluating\n",
    "\n",
    "performance, trees = k_fold_performance(k_fold_validation(k, x_train, y_train))\n",
    "print(f\"Average Training Accuracy, over {k} validations: {sum(performance['Training Set Accuracy'])/len(performance['Training Set Accuracy'])}%\")\n",
    "\n",
    "# This contains the tree models, and their respective performances\n",
    "\n",
    "df = pd.DataFrame(performance)\n",
    "df.index.names = ['Validation']\n",
    "df.columns.names = ['Metrics']\n",
    "df\n",
    "\n",
    "#Run the K fold Validation and report the scores\n",
    "\n",
    "#######################\n",
    "# Your code goes here #\n",
    "#######################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the testing Set (Random Forests): 95.11400651465797%\n",
      "Accuracy on the testing Set (Random Forests): 95.87404994571118%\n",
      "Accuracy on the testing Set (Random Forests): 95.22258414766557%\n",
      "Accuracy on the testing Set (Random Forests): 95.87404994571118%\n",
      "Accuracy on the testing Set (Random Forests): 95.87404994571118%\n",
      "Accuracy on the testing Set (Random Forests): 95.54831704668838%\n",
      "Accuracy on the testing Set (Random Forests): 96.09120521172639%\n",
      "Accuracy on the testing Set (Random Forests): 96.09120521172639%\n",
      "Accuracy on the testing Set (Random Forests): 96.09120521172639%\n",
      "Accuracy on the testing Set (Random Forests): 95.98262757871878%\n",
      "Accuracy on the testing Set (Random Forests): 95.65689467969598%\n",
      "Accuracy on the testing Set (Random Forests): 95.43973941368078%\n",
      "Accuracy on the testing Set (Random Forests): 95.98262757871878%\n",
      "Accuracy on the testing Set (Random Forests): 96.19978284473399%\n",
      "Accuracy on the testing Set (Random Forests): 95.76547231270358%\n",
      "Accuracy on the testing Set (Random Forests): 95.76547231270358%\n",
      "Accuracy on the testing Set (Random Forests): 95.43973941368078%\n",
      "Accuracy on the testing Set (Random Forests): 95.54831704668838%\n",
      "Accuracy on the testing Set (Random Forests): 95.65689467969598%\n",
      "Accuracy on the testing Set (Random Forests): 95.54831704668838%\n",
      "Accuracy on the testing Set (Random Forests): 95.98262757871878%\n",
      "Accuracy on the testing Set (Random Forests): 95.76547231270358%\n",
      "Accuracy on the testing Set (Random Forests): 95.65689467969598%\n",
      "Accuracy on the testing Set (Random Forests): 95.65689467969598%\n",
      "Accuracy on the testing Set (Random Forests): 95.87404994571118%\n",
      "Accuracy on the testing Set (Random Forests): 95.33116178067318%\n",
      "Accuracy on the testing Set (Random Forests): 95.87404994571118%\n",
      "Accuracy on the testing Set (Random Forests): 95.76547231270358%\n",
      "Accuracy on the testing Set (Random Forests): 95.87404994571118%\n",
      "Accuracy on the testing Set (Random Forests): 95.87404994571118%\n",
      "Accuracy on the testing Set (Random Forests): 95.65689467969598%\n",
      "Accuracy on the testing Set (Random Forests): 95.98262757871878%\n",
      "Accuracy on the testing Set (Random Forests): 95.65689467969598%\n",
      "Accuracy on the testing Set (Random Forests): 95.33116178067318%\n",
      "Accuracy on the testing Set (Random Forests): 95.76547231270358%\n",
      "Accuracy on the testing Set (Random Forests): 95.87404994571118%\n",
      "Accuracy on the testing Set (Random Forests): 95.98262757871878%\n",
      "Accuracy on the testing Set (Random Forests): 95.54831704668838%\n",
      "Accuracy on the testing Set (Random Forests): 95.87404994571118%\n",
      "Accuracy on the testing Set (Random Forests): 95.54831704668838%\n",
      "Accuracy on the testing Set (Random Forests): 95.22258414766557%\n",
      "Accuracy on the testing Set (Random Forests): 95.43973941368078%\n",
      "Accuracy on the testing Set (Random Forests): 95.87404994571118%\n",
      "Accuracy on the testing Set (Random Forests): 95.65689467969598%\n",
      "Accuracy on the testing Set (Random Forests): 95.54831704668838%\n",
      "Accuracy on the testing Set (Random Forests): 96.30836047774159%\n",
      "Accuracy on the testing Set (Random Forests): 95.76547231270358%\n",
      "Accuracy on the testing Set (Random Forests): 95.76547231270358%\n",
      "Accuracy on the testing Set (Random Forests): 95.54831704668838%\n",
      "Accuracy on the testing Set (Random Forests): 95.76547231270358%\n",
      "0.9573072747014116\n"
     ]
    }
   ],
   "source": [
    "def ensemble_components(components, x_train, y_train, n_prime):\n",
    "    ensemble = []\n",
    "    for _ in range(components):\n",
    "        clf = DecisionTreeClassifier(max_features= 5)\n",
    "        # Selecting features\n",
    "        rand_idx = np.random.randint(0, x_train.shape[0], n_prime)\n",
    "        train_labels = y_train[rand_idx]\n",
    "        train_set = x_train[rand_idx]\n",
    "        # bagging \n",
    "        clf.fit(train_set, train_labels)\n",
    "        ensemble += [clf]\n",
    "    return ensemble\n",
    "\n",
    "def random_forest_algorithm(number_of_trees, x_train, y_train, n_prime): # Pass necessary params as per requirements\n",
    "    '''\n",
    "    This function intends to return the indivdual trees,\n",
    "    which are going to be used for predicting the ensemble\n",
    "    '''\n",
    "    ensemble = ensemble_components(number_of_trees, x_train, y_train, n_prime)\n",
    "    return ensemble\n",
    "\n",
    "\n",
    "def test(ensemble, test_set, test_labels):\n",
    "    preds = [i.predict(test_set) for i in ensemble]\n",
    "    preds = np.array(preds)\n",
    "    preds = np.mean(preds, axis = 0)\n",
    "    for i in range(len(preds)):\n",
    "        if(preds[i] >= 0.5):\n",
    "            preds[i] = 1\n",
    "        else:\n",
    "            preds[i] = 0\n",
    "    preds = preds.astype(int)\n",
    "    score = accuracy_score(test_labels, preds)\n",
    "    return preds, score\n",
    "\n",
    "temp_1 = []\n",
    "for _ in range(50):\n",
    "    ensembles = random_forest_algorithm(100, x_train, y_train,( (len(x_train)*9)//10))\n",
    "    test_preds, score = test(ensembles, x_test, y_test)\n",
    "    print(f\"Accuracy on the testing Set (Random Forests): {score*100}%\")\n",
    "    temp_1 += [score]\n",
    "print(np.mean(temp_1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#######################\n",
    "# Your code goes here #\n",
    "#######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9630836047774158"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(temp_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = [\n",
    "0.30536\n",
    ",1.2906\n",
    ",0.50414\n",
    ",1.3952\n",
    ",0.67251\n",
    ",0.27382\n",
    ",0.39144\n",
    ",0.40107\n",
    ",0.27862\n",
    ",0.64476\n",
    ",0.20154\n",
    ",0.8617\n",
    ",0.30104\n",
    ",0.33518\n",
    ",0.25884\n",
    ",0.82579\n",
    ",0.44406\n",
    ",0.53112\n",
    ",1.7755\n",
    ",0.50977\n",
    ",1.2008\n",
    ",1.0258\n",
    ",0.35029\n",
    ",0.44264\n",
    ",1.6713\n",
    ",0.88696\n",
    ",3.3673\n",
    ",0.53858\n",
    ",0.59333\n",
    ",0.45668\n",
    ",0.40339\n",
    ",0.32856\n",
    ",0.55591\n",
    ",0.32945\n",
    ",0.53226\n",
    ",0.40262\n",
    ",0.42345\n",
    ",0.22065\n",
    ",0.43467\n",
    ",0.34992\n",
    ",0.3612\n",
    ",0.76682\n",
    ",0.22381\n",
    ",0.62198\n",
    ",1.0117\n",
    ",0.91112\n",
    ",0.076274\n",
    ",0.28573\n",
    ",0.24347\n",
    ",0.27036\n",
    ",0.10939\n",
    ",0.81567\n",
    ",0.24588\n",
    ",0.42934\n",
    ",31.729\n",
    ",194.89\n",
    ",606.35\n",
    ",0.4887\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([46, 50, 10, 37, 42, 48, 52, 14, 49,  5,  8, 47, 12,  0, 31, 33, 13,\n",
       "       39, 22, 40,  6,  7, 35, 30, 36, 53, 38, 23, 16, 29, 57,  2, 19, 17,\n",
       "       34, 27, 32, 28, 43,  9,  4, 41, 51, 15, 11, 25, 45, 44, 21, 20,  1,\n",
       "        3, 24, 18, 26, 54, 55, 56])"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.6274e-02, 1.0939e-01, 2.0154e-01, 2.2065e-01, 2.2381e-01,\n",
       "       2.4347e-01, 2.4588e-01, 2.5884e-01, 2.7036e-01, 2.7382e-01,\n",
       "       2.7862e-01, 2.8573e-01, 3.0104e-01, 3.0536e-01, 3.2856e-01,\n",
       "       3.2945e-01, 3.3518e-01, 3.4992e-01, 3.5029e-01, 3.6120e-01,\n",
       "       3.9144e-01, 4.0107e-01, 4.0262e-01, 4.0339e-01, 4.2345e-01,\n",
       "       4.2934e-01, 4.3467e-01, 4.4264e-01, 4.4406e-01, 4.5668e-01,\n",
       "       4.8870e-01, 5.0414e-01, 5.0977e-01, 5.3112e-01, 5.3226e-01,\n",
       "       5.3858e-01, 5.5591e-01, 5.9333e-01, 6.2198e-01, 6.4476e-01,\n",
       "       6.7251e-01, 7.6682e-01, 8.1567e-01, 8.2579e-01, 8.6170e-01,\n",
       "       8.8696e-01, 9.1112e-01, 1.0117e+00, 1.0258e+00, 1.2008e+00,\n",
       "       1.2906e+00, 1.3952e+00, 1.6713e+00, 1.7755e+00, 3.3673e+00,\n",
       "       3.1729e+01, 1.9489e+02, 6.0635e+02])"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments\n",
    "- Looking at the documentation, we can remove the features, with the lowest variance and try all the algorithms. Since, the features with the lowest variance are least spread out, they might not conribute much to the variance.\n",
    "  - Outcomes\n",
    "    - Removing: Column 47 - Variance 7e-2\n",
    "      - RF - 95.5% average test accuracy\n",
    "      - DT - Highest Accuracy in 15-Fold CV - 92.2%\n",
    "    - "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
